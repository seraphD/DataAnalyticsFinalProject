{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a6c8cccf23fc189a51b8b2ae4ca3b98de763e12cce4f9033fe8d82721c91cecc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Ks import *\n",
    "import pickle as pkl\n",
    "\n",
    "# load data\n",
    "f = open(\"data.pickle\", \"rb\")\n",
    "data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i in data:\n",
    "    tmp = [i.bigCategory, i.day, i.goal, i.backers]\n",
    "    features.append(tmp)\n",
    "    labels.append(i.pleged)\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, normalize\n",
    "\n",
    "# one hot encode category\n",
    "category = X[:, [0]]\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "category = enc.fit_transform(category).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max normalize numeric features\n",
    "d = X[:, [1,2,3]]\n",
    "d = normalize(d, axis=0, norm=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((category, d), axis=1)"
   ]
  },
  {
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "# K-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(X)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# use odd K to avoid tie\n",
    "for i in range(11, 20, 2):\n",
    "\n",
    "    for j, [train_index, test_index] in enumerate(kf.split(X)):\n",
    "        X_train = X[train_index, :]\n",
    "        y_train = y[train_index]\n",
    "\n",
    "        X_test = X[test_index, :]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        print(\"Building on K={} fold={}\".format(i, j))\n",
    "        neigh = NearestNeighbors(n_neighbors=i)\n",
    "        neigh.fit(X_train)\n",
    "\n",
    "        print(\"Testing...\")\n",
    "        n = neigh.kneighbors(X_test, i, return_distance=False)\n",
    "        pledge_predict = []\n",
    "        state_predict = []\n",
    "        actual_state = []\n",
    "\n",
    "        for inx, nbrs in enumerate(n):\n",
    "            nbrPlege = y_train[nbrs]\n",
    "            p = np.mean(nbrPlege)\n",
    "            pledge_predict.append(p)\n",
    "            \n",
    "            goal = X_test[inx][2]\n",
    "            state = X_test[inx][2] >= y_test[inx]\n",
    "            actual_state.append(state)\n",
    "\n",
    "            # goal = X_test[inx][2]\n",
    "            # state = X_test[inx][2] >= y_test[inx]\n",
    "            # actual_state.append(state)\n",
    "\n",
    "            if (p >= goal and state) or (p < goal and not state):\n",
    "                state_predict.append(True)\n",
    "            else:\n",
    "                state_predict.append(False)\n",
    "        \n",
    "        RMSE = np.sqrt((np.square(pledge_predict - y_test).mean(axis=0)))\n",
    "        tn, fp, fn, tp = confusion_matrix(state_predict, actual_state).ravel()\n",
    "        acc = accuracy_score(actual_state, state_predict)\n",
    "        \n",
    "        print(\"           Positive       Negative\")\n",
    "        print(\"Positive     {}             {}\".format(tn, fp))\n",
    "        print(\"Negative     {}             {}\".format(fn, tp))\n",
    "\n",
    "        print(classification_report(state_predict, actual_state))\n",
    "        print(\"Accuracy: {}\".format(acc))\n",
    "        print(\"RMSE: {}\".format(RMSE))\n",
    "\n",
    "        if acc > best_acc:\n",
    "            # save best classifier\n",
    "            clf = open(\"KNN_clf.pkl\", \"wb\")\n",
    "            pkl.dump(neigh, clf)\n",
    "            clf.close()\n",
    "            break\n",
    "    break"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building on K=11 fold=0\n",
      "Testing...\n",
      "           Positive       Negative\n",
      "Positive     94884             255\n",
      "Negative     0             14077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     95139\n",
      "        True       0.98      1.00      0.99     14077\n",
      "\n",
      "    accuracy                           1.00    109216\n",
      "   macro avg       0.99      1.00      0.99    109216\n",
      "weighted avg       1.00      1.00      1.00    109216\n",
      "\n",
      "Accuracy: 0.9976651772634046\n",
      "RMSE: 61332.5808016165\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}